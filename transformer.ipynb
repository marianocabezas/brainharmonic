{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3500ad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import os\n",
    "from mido.midifiles.meta import KeySignatureError\n",
    "from mido import MidiFile\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from functools import partial\n",
    "from copy import deepcopy\n",
    "from base import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "719d0261",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'samples/music/maestro/'\n",
    "\n",
    "files = os.listdir(test_path)\n",
    "mpb = []\n",
    "tpb = []\n",
    "f_files = []\n",
    "rolls = []\n",
    "for f in sorted(files)[:100]:\n",
    "    try:\n",
    "        t = 0\n",
    "        note_found = False\n",
    "        discard = False\n",
    "        mpb_i = None\n",
    "        mid_temp = MidiFile(os.path.join(test_path, f), clip=True)\n",
    "        notes = {\n",
    "            n: {'start': [], 'end': [], 'velocity': []}\n",
    "            for n in range(128)\n",
    "        }\n",
    "        for track in mid_temp.tracks:\n",
    "            for msg in track:\n",
    "                if not msg.is_meta:\n",
    "                    if msg.type == 'note_on':\n",
    "                        if note_found:\n",
    "                            t += msg.time\n",
    "                        else:\n",
    "                            t = 0\n",
    "                            note_found = True\n",
    "                        if msg.velocity > 0:\n",
    "                            notes[msg.note]['start'].append(t // mid_temp.ticks_per_beat)\n",
    "                            notes[msg.note]['velocity'].append(msg.velocity)\n",
    "                        else:\n",
    "                            notes[msg.note]['end'].append(t // mid_temp.ticks_per_beat)\n",
    "                    if msg.type == 'note_off':\n",
    "                        t += msg.time\n",
    "                        notes[msg.note]['end'].append(t // mid_temp.ticks_per_beat)\n",
    "                else:\n",
    "                    if msg.type == 'set_tempo':\n",
    "                        if mpb_i is None:\n",
    "                            mpb_i = msg.tempo\n",
    "                        else:\n",
    "                            discard = True\n",
    "                    elif msg.type == 'time_signature':\n",
    "                        if msg.numerator != 4 and  msg.denominator != 4:\n",
    "                            print(msg)\n",
    "\n",
    "        if not discard:\n",
    "            f_files.append(f) \n",
    "            tpb.append(mid_temp.ticks_per_beat)\n",
    "            mpb.append(mpb_i)\n",
    "            piano_roll = np.zeros((128, t // mid_temp.ticks_per_beat))\n",
    "            for n, events in notes.items():\n",
    "                if len(events['start']) > 0:\n",
    "                    for n_ini, n_end, v in zip(events['start'], events['end'], events['velocity']):\n",
    "                        piano_roll[n, n_ini:n_end] = v / 127\n",
    "            rolls.append(piano_roll)\n",
    "    except EOFError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6ff4fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_logits(logits, target):\n",
    "    prediction = torch.max(logits, dim=1)[1]\n",
    "    return 1 - (prediction == target).float().mean()\n",
    "    \n",
    "    \n",
    "class SelfAttentionBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, mlp_dim, heads):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(embed_dim, eps=1e-6)\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim, heads, batch_first=True\n",
    "        )\n",
    "        self.ln2 = nn.LayerNorm(embed_dim, eps=1e-6)\n",
    "        self.mlp = nn.Linear(embed_dim, mlp_dim)\n",
    "\n",
    "    def forward(self, x_in, mask=None):\n",
    "        x = self.ln1(x_in)\n",
    "        x, _ = self.attention(\n",
    "            query=x, key=x, value=x, attn_mask=mask,\n",
    "            need_weights=False,\n",
    "        )\n",
    "        x = x + x_in\n",
    "\n",
    "        y = self.ln2(x)\n",
    "        y = self.mlp(y)\n",
    "\n",
    "        return x + y\n",
    "    \n",
    "\n",
    "class MusicTransformer(BaseModel):\n",
    "    \"\"\"\n",
    "        Transformer architecture for motifs inspired by\n",
    "        C.-Z. A. Huang, A. Vaswani, J. Uszkoreit, N. Shazeer,\n",
    "        I. Simon, C. Hawthorne, A. M. Dai, M. D. Hoffman,\n",
    "        M. Dinculescu and D. Eck\n",
    "        \"Music Transformer\"\n",
    "        https://arxiv.org/abs/1809.04281\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder_depth=16,\n",
    "        decoder_depth=16,\n",
    "        device=torch.device(\n",
    "            \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        ),\n",
    "        notes=128,\n",
    "        bits=8,\n",
    "        multitokens=True,\n",
    "        heads=32,\n",
    "        lr=1e-3,\n",
    "        verbose=0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Init values\n",
    "        self.epoch = None\n",
    "        self.t_train = 0\n",
    "        self.t_val = 0\n",
    "        self.heads = heads\n",
    "        self.device = device\n",
    "        self.multitokens = multitokens\n",
    "        if self.multitokens:            \n",
    "            channels = notes\n",
    "        else:\n",
    "            channels = 2 * notes + bits\n",
    "\n",
    "        # <Parameter setup>\n",
    "        self.encoder = nn.ModuleList([\n",
    "            SelfAttentionBlock(channels, channels, heads)\n",
    "            for _ in range(encoder_depth)\n",
    "        ])\n",
    "        self.decoder = nn.ModuleList([\n",
    "            SelfAttentionBlock(channels, channels, heads)\n",
    "            for _ in range(decoder_depth)\n",
    "        ])\n",
    "\n",
    "        # <Loss function setup>\n",
    "        if self.multitokens:\n",
    "            self.train_functions = [\n",
    "                {\n",
    "                    'name': 'xent',\n",
    "                    'weight': 1,\n",
    "                    'f': F.binary_cross_entropy_with_logits\n",
    "                },\n",
    "            ]\n",
    "            \n",
    "            self.val_functions = [\n",
    "                {\n",
    "                    'name': 'xent',\n",
    "                    'weight': 1,\n",
    "                    'f': F.binary_cross_entropy_with_logits\n",
    "                },\n",
    "                {\n",
    "                    'name': 'mse',\n",
    "                    'weight': 0,\n",
    "                    'f': lambda p, t: F.mse_loss(\n",
    "                        torch.sigmoid(p), t,\n",
    "                    )\n",
    "                },\n",
    "                {\n",
    "                    'name': 'l1',\n",
    "                    'weight': 0,\n",
    "                    'f': lambda p, t: F.l1_loss(\n",
    "                        torch.sigmoid(p), t,\n",
    "                    )\n",
    "                },\n",
    "                {\n",
    "                    'name': '0mse',\n",
    "                    'weight': 0,\n",
    "                    'f': lambda p, t: F.mse_loss(\n",
    "                        torch.zeros_like(t).to(t.device), t,\n",
    "                    )\n",
    "                },\n",
    "                {\n",
    "                    'name': '1mse',\n",
    "                    'weight': 0,\n",
    "                    'f': lambda p, t: F.mse_loss(\n",
    "                        torch.ones_like(t).to(t.device), t,\n",
    "                    )\n",
    "                },\n",
    "            ]\n",
    "        else:\n",
    "            self.train_functions = [\n",
    "                {\n",
    "                    'name': 'xent',\n",
    "                    'weight': 1,\n",
    "                    'f': F.cross_entropy\n",
    "                },\n",
    "            ]\n",
    "            \n",
    "            self.val_functions = [\n",
    "                {\n",
    "                    'name': 'xent',\n",
    "                    'weight': 0,\n",
    "                    'f': F.cross_entropy\n",
    "                },\n",
    "                {\n",
    "                    'name': 'acc',\n",
    "                    'weight': 1,\n",
    "                    'f': accuracy_logits\n",
    "                },\n",
    "            ]\n",
    "\n",
    "        # <Optimizer setup>\n",
    "        # We do this last step after all parameters are defined\n",
    "        model_params = filter(lambda p: p.requires_grad, self.parameters())\n",
    "        self.optimizer_alg = torch.optim.Adam(model_params, lr=lr)\n",
    "        self.schedulers = [\n",
    "            torch.optim.lr_scheduler.ExponentialLR(\n",
    "                self.optimizer_alg, gamma=0.9\n",
    "            ),\n",
    "            torch.optim.lr_scheduler.MultiStepLR(\n",
    "                self.optimizer_alg, milestones=[10, 30, 50, 80], gamma=0.1\n",
    "            ),\n",
    "            torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                self.optimizer_alg, 'min'\n",
    "            )\n",
    "        ]\n",
    "        if verbose > 1:\n",
    "            print(\n",
    "                'Network created on device {:} with training losses '\n",
    "                '[{:}] and validation losses [{:}]'.format(\n",
    "                    self.device,\n",
    "                    ', '.join([tf['name'] for tf in self.train_functions]),\n",
    "                    ', '.join([vf['name'] for vf in self.val_functions])\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def forward(self, data):\n",
    "        N, F, L = data.shape\n",
    "        mask = torch.ones((L, L), dtype=bool)\n",
    "        mask = torch.logical_not(torch.triu(mask)).to(self.device)\n",
    "        seq_range = torch.arange(0, data.shape[-1])\n",
    "        x_cord, y_cord = torch.meshgrid(seq_range, seq_range)\n",
    "        s_rel = 1 - torch.abs(x_cord - y_cord).type_as(data).to(data.device)\n",
    "        snorm_rel = s_rel / L\n",
    "        data = data.transpose(-1, -2)\n",
    "        for i, e_tf in enumerate(self.encoder):\n",
    "            e_tf.to(self.device)\n",
    "            data = e_tf(data, snorm_rel)\n",
    "        for i, d_tf in enumerate(self.decoder):\n",
    "            d_tf.to(self.device)\n",
    "            data = d_tf(data, mask)\n",
    "        return data.transpose(-1, -2)\n",
    "\n",
    "    def next_beat(self, motif):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            tensor_motif = torch.from_numpy(\n",
    "                np.expand_dims(motif, axis=0)\n",
    "            ).to(self.device)\n",
    "            if self.multitokens:\n",
    "                next_beat = torch.sigmoid(self(tensor_motif))\n",
    "            else:\n",
    "                next_beat = torch.softmax(self(tensor_motif), dim=1)\n",
    "\n",
    "        return next_beat.detach().cpu().numpy()[0, ...]\n",
    "\n",
    "    def song(self, motif, n_beats):\n",
    "        song_list = [motif]\n",
    "        song = [motif]\n",
    "        for _ in range(n_beats):\n",
    "            beat = self.next_beat(motif)\n",
    "            new_notes = deepcopy(beat)\n",
    "            if self.multitokens:\n",
    "                motif = (new_notes > 0.5).astype(np.float32)\n",
    "                song_list.append(\n",
    "                    beat\n",
    "                )\n",
    "                song.append(\n",
    "                    new_notes > 0.5\n",
    "                )\n",
    "            else:\n",
    "                new_tokens = deepcopy(beat)\n",
    "                max_val = np.max(new_tokens, axis=0, keepdims=True)\n",
    "                motif = (new_tokens == max_val).astype(np.float32)\n",
    "                song_list.append(\n",
    "                    beat\n",
    "                )\n",
    "                song.append(\n",
    "                    new_tokens == max_val\n",
    "                )\n",
    "\n",
    "        return np.concatenate(song_list, axis=1), np.concatenate(song, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f31c2595",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MotifDataset(Dataset):\n",
    "    def __init__(\n",
    "            self, paths=None, motif_size=64, notespbeat=12,\n",
    "            bits=8, multitokens=True\n",
    "    ):\n",
    "        # Init\n",
    "        if paths is None:\n",
    "            paths = ['samples/music/jazz/', 'samples/music/classical/']\n",
    "        self.multitokens = multitokens\n",
    "        self.motif_size = motif_size\n",
    "        self.rolls = []\n",
    "        self.states = []\n",
    "        self.bits = bits\n",
    "        min_len = 2 * self.motif_size + 1\n",
    "        beat = 0\n",
    "        for path in paths:\n",
    "            files = sorted(os.listdir(path))\n",
    "            for f in files:\n",
    "                t = 0\n",
    "                discard = False\n",
    "                mpb_i = None\n",
    "                note_found = False\n",
    "                try:\n",
    "                    mid_temp = MidiFile(os.path.join(path, f), clip=True)\n",
    "                    notes = {\n",
    "                        n: {'start': [], 'end': [], 'velocity': []}\n",
    "                        for n in range(128)\n",
    "                    }\n",
    "                    tpb = mid_temp.ticks_per_beat\n",
    "                    for track in mid_temp.tracks:\n",
    "                        for msg in track:\n",
    "                            if not msg.is_meta:\n",
    "                                if note_found:\n",
    "                                    t += msg.time\n",
    "                                if msg.type == 'note_on':\n",
    "                                    if not note_found:\n",
    "                                        t = 0\n",
    "                                        note_found = True\n",
    "                                    beat = t // tpb\n",
    "                                    if msg.velocity > 0:\n",
    "                                        notes[msg.note]['start'].append(beat)\n",
    "                                        notes[msg.note]['velocity'].append(\n",
    "                                            msg.velocity\n",
    "                                        )\n",
    "                                    else:\n",
    "                                        notes[msg.note]['end'].append(beat)\n",
    "                                elif msg.type == 'note_off':\n",
    "                                    beat = t // tpb\n",
    "                                    notes[msg.note]['end'].append(beat)\n",
    "                            else:\n",
    "                                if msg.type == 'set_tempo':\n",
    "                                    if mpb_i is None:\n",
    "                                        mpb_i = msg.tempo\n",
    "                                    else:\n",
    "                                        discard = True\n",
    "                                        break\n",
    "                                elif msg.type == 'time_signature':\n",
    "                                    num = msg.numerator\n",
    "                                    den = msg.denominator\n",
    "                                    if num != 4 and den != 4:\n",
    "                                        discard = True\n",
    "                                        break\n",
    "\n",
    "                    if not discard:\n",
    "                        piano_roll = np.zeros((128, beat))\n",
    "                        for n, events in notes.items():\n",
    "                            if len(events['start']) > 0:\n",
    "                                for n_ini, n_end, v in zip(\n",
    "                                        events['start'], events['end'],\n",
    "                                        events['velocity']\n",
    "                                ):\n",
    "                                    # piano_roll[n, n_ini:n_end] = v / 127\n",
    "                                    piano_roll[n, n_ini:n_end] = 1\n",
    "                        max_notes = np.max(\n",
    "                            np.sum(piano_roll, axis=0)\n",
    "                        ).astype(int)\n",
    "                        piano_state = roll_to_state(\n",
    "                            piano_roll, bits=self.bits\n",
    "                        )\n",
    "                        roll_len = piano_roll.shape[1]\n",
    "                        if roll_len > min_len and max_notes < notespbeat:\n",
    "                            self.rolls.append(piano_roll)\n",
    "                        state_len = piano_state.shape[1]\n",
    "                        if state_len > min_len and max_notes < notespbeat:\n",
    "                            self.states.append(piano_state)\n",
    "                except (EOFError, OSError, KeySignatureError):\n",
    "                    print('Unreadable', f, path)\n",
    "\n",
    "        max_notes = [\n",
    "            np.max(np.sum(roll, axis=0)).astype(int)\n",
    "            for roll in self.rolls\n",
    "        ]\n",
    "        print(\n",
    "            '{:d} piano rolls loaded with '\n",
    "            '[{:02d}, {:02d}] - {:5.3f} Â± {:5.3f} '\n",
    "            'maximum consecutive notes'.format(\n",
    "                len(self.rolls), np.min(max_notes), np.max(max_notes),\n",
    "                np.mean(max_notes), np.std(max_notes)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.multitokens:\n",
    "            song = self.rolls[index]\n",
    "        else:\n",
    "            song = self.states[index]\n",
    "        max_ini = song.shape[1] - (2 * self.motif_size)\n",
    "        data_ini = np.random.randint(0, max_ini)\n",
    "        target_ini = data_ini + self.motif_size\n",
    "        data = song[:, data_ini:target_ini].astype(np.float32)\n",
    "        target = song[:, target_ini:(target_ini + self.motif_size)].astype(np.float32)\n",
    "        if not self.multitokens:\n",
    "            target = np.argmax(target, axis=0)\n",
    "\n",
    "        return data, target\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.multitokens:\n",
    "            n_samples = len(self.rolls)\n",
    "        else:\n",
    "            n_samples = len(self.states)\n",
    "        return n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42ea036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_tokens(shift, bits=4, notes=128):\n",
    "    remainder = shift\n",
    "    tokens = []\n",
    "    for shift_bit in range(bits - 1, -1, -1):\n",
    "        token = np.zeros(2 * notes + bits)\n",
    "        token[2 * notes + shift_bit] = 1\n",
    "        n_tokens = remainder // 2 ** shift_bit\n",
    "        remainder = remainder - n_tokens * 2 ** shift_bit\n",
    "        tokens += n_tokens * [token]\n",
    "        \n",
    "    return tokens\n",
    "\n",
    "\n",
    "def on_tokens(note_list, bits=4, notes=128):\n",
    "    tokens = []\n",
    "    for note in note_list:\n",
    "        token = np.zeros(2 * notes + bits)\n",
    "        token[note] = 1\n",
    "        tokens.append(token)\n",
    "        \n",
    "    return tokens\n",
    "\n",
    "\n",
    "def off_tokens(note_list, bits=4, notes=128):\n",
    "    tokens = []\n",
    "    for note in note_list:\n",
    "        token = np.zeros(2 * notes + bits)\n",
    "        token[notes + note] = 1\n",
    "        tokens.append(token)\n",
    "        \n",
    "    return tokens\n",
    "\n",
    "\n",
    "def roll_to_state(roll, bits=8, notes=128):\n",
    "    shift = 0\n",
    "    notes_active = np.array([])\n",
    "    token_list = []\n",
    "    for beat in roll.transpose():\n",
    "        if np.sum(beat) > 0:\n",
    "            played_notes = np.where(beat > 0)[0]\n",
    "            new_replayed = np.isin(played_notes, notes_active)\n",
    "            old_replayed = np.isin(notes_active, played_notes)\n",
    "            if new_replayed.all() and old_replayed.all():\n",
    "                # We are repeating everything\n",
    "                # print('Repeat', notes_active, played_notes, shift)\n",
    "                pass\n",
    "            else:\n",
    "                # Changes\n",
    "                on = played_notes[np.logical_not(new_replayed)]\n",
    "                off = notes_active[np.logical_not(old_replayed)]\n",
    "                # print(\n",
    "                #     'OFF', off, 'ON', on, 'Data', notes_active, old_replayed,\n",
    "                #     played_notes, new_replayed, shift\n",
    "                # )\n",
    "                token_list += shift_tokens(shift, bits, notes)\n",
    "                token_list += off_tokens(off, bits, notes)\n",
    "                token_list += on_tokens(on, bits, notes)\n",
    "                shift = 0\n",
    "            notes_active = played_notes\n",
    "        else:\n",
    "            if len(notes_active) == 0:\n",
    "                # Silence\n",
    "                # print('Silence', shift)\n",
    "                pass\n",
    "            else:\n",
    "                # Notes go off\n",
    "                # print('OFF', notes_active, shift)\n",
    "                token_list += shift_tokens(shift, bits, notes)\n",
    "                token_list += off_tokens(notes_active, bits, notes)\n",
    "                notes_active = np.array([])\n",
    "                shift = 0\n",
    "\n",
    "        shift += 1\n",
    "        \n",
    "    token_list += shift_tokens(shift, bits, notes)\n",
    "    \n",
    "    return np.stack(token_list, axis=1)\n",
    "\n",
    "\n",
    "def state_to_roll(states, bits=8, notes=128):\n",
    "    roll = []\n",
    "    active_notes = []\n",
    "    for state in states.transpose():\n",
    "        state_code = np.where(state)[0][0]\n",
    "        if state_code < notes:\n",
    "            # print('ON', state_code)\n",
    "            active_notes.append(state_code)\n",
    "        elif state_code < (2 * notes):\n",
    "            # print('OFF', state_code - notes)\n",
    "            try:\n",
    "                active_notes.remove(state_code - notes)\n",
    "            except ValueError:\n",
    "                pass\n",
    "        else:\n",
    "            # print('Shift', 2 ** (state_code - 2 * notes))\n",
    "            shift = 2 ** (state_code - 2 * notes)\n",
    "            beat = np.zeros(notes)\n",
    "            for note in active_notes:\n",
    "                beat[note] = 1\n",
    "            roll += shift * [beat]\n",
    "    \n",
    "    return np.stack(roll, axis=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c61d348",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAKaCAYAAACdjYomAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVlElEQVR4nO3dfYhl50HH8WfidCFtNm9NQ5JFKjGpSY3pizbW0BCDEY0QRFMMBasgohQKUmixKDS0oFQqFLESFC1oBYm0iPaPKkRD2BJrqg1iaqKJoVJ3jG2al93Gkc3a6x/rnLnZ3Pd7zu+8fT7/7GHuzp0z95z7vc99zjl3diaTSQEg47y2VwBgTEQXIEh0AYJEFyBIdAGCdhfeeOSYUxsA1nTm9ImdebcZ6QIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBO22vQIAffD1O6+t5X52JpPJ3Bt3jxybfyMAM505fWJn3m2mFwCCRBcgSHQBgkQXIMjZCy174vo3VsvXPvbPLa4JkODsBYCaLTp7wUi3Qx459tZq+S0nvlRKmT8Sfvbdh1+/9FNnv/6Nu6+rvvba+x6vlk/cfPb8wmMPPbHw5//hZbdVyz/7zANrrfuqPnrFba/42gefbuZnjcn0trv9Df9RLR9s8y9ffWP1tYuv2K+WH378ylJKKUcnZ6qvvf6K56tl777qZ6QLUDMj3TU993PfUy1f8sl/anFN2vPChw5HThd9xEgU6mKkC1AzV6QBdIToAr3zyLG3vuzAc58snNOdPho+bfrIOEDC9BkY3/3Ul1pck+2Y04WReeGDt1TLJ//mv0oppXz7w//a1uoM0qI5XdEFqJlTxqCDPnfJO6rlO577fKM/a3p0e9FHjzf6s1jMSJfBG/M5x8/9wptKKaVc8nv/2PKajIvpBbZy8tfvqJYv/JXPtbgm/fXFK76vWn7b03/f4pp018GL4xBeGEWXUTp177tKKaUcfc+ftLwmjI3o9sTj19zwiq9d9qbTh8ufOTzCfBCUUg6jMj0infa/X9krpZTy5F+8qvrarNHWJ193+Db8x278arV8xV8/uXTdybvnyh+slu/afb5avvLNL1bLr/vs4g85OjC97138+v+pluvc9gcj2fNufHP1tW99+fAy+4vuuX/h9//O5Yf7503nnSqllHLpZYe/63c++lgdq1kLV6QBdISRLvTMpy+9tZRSyjuffbDlNWEe0wuMhk+IY57kAWHRbcEDl/5AKaWU257925bXZLie/qFrSimlnNo7Un2tzg/d/sLlb6uW3/61L9Z2v/dfcnMppZTbn3uotvukW0SXtT3/3u+tli/+xD+0uCbQP41F94UP314tLzvyCHVoevrg1KffVy0ffefHa79/xsFIl1H75hfurZYvePt7WlwTxkJ0Wejgc0kP/hhmV6z6BzXr8N9P/WUppZRXX/2jjf+sg7niOueJ6RbRpde+fue11fKqJ/unfeUt31VKKeU7HvmXltekGaYS1yO6AEE+2rFFX7vjmmr58s91+3Lar970hmrZh1rXqw+j9Vme/6WbSimlXPxbD9d2nyc/8VPV8oXv/dPa7ncdp37/Z0oppRz9+T+K/2yXAQMEmV4YqekPOLnuyUdbXBMYno3ndPf/4P3VjWP4eLyDT9ef98n6B1dArfLJS/92w/WllG598lHCNx/8zVJKKRfc+v7Gf9bBB3SXM9+qvubS380cnClSyuZniyS3fdeN+kDaqT//5Wr56I//Rotr0l3rvJgwfD60fnujji7DIgj0geh2kL9d1b4XH/tMtfya6+9qcU0YmtFF15QCbXni+jdWy3V+4hn9Eo/uQfTGFrxv3H1dtfza+x5vcU2We+EDN1fLF31s/Y8YPHX/r1XLR2//1VrWaZ6xXg31n7cenuN95YOH8+0HZ55setbJwTmqpZRy5qFHSikOQNZtdCNdgDaN4oq0rv6J6y6Nfrv6VxWmr9aa9m0Xn/1Dmpd+qr636S8+el+1/Job7q7tfmc5uJqrlJdf0XVwlWLyCkUfWTnbqb/6cLV89EfuifxMV6QBBJleaMjBqHLZiPKZuw4/72D6T6wv4zNi++/g/OhSZp8jXV38UZo7y+Xkx+4spZRy4Qc+28j9j5U53ZocHNAZ08Echufkx3+iWr7wfX/W4poMl+gO3P7e2cuWz7/qlpbXhOkzA+Z9gtWsd0HTf5PupX8/WUp5+aeRvfCh26rliz7ywMrrc3AxiQtJskQXRs6BtKxaotv0BQfrzF+5FLRbTt37rmp5DB+MVJeDD1gqZf6HLG3i2XcfXqBR55kfrM5Il1KKubw2tfXB3QcjXKPbLNEFWKLOd2yiCy1Inng/fVl3ueDV1aIzbdrRiehOX5l15Cd/uJRSytG7f3vp95364188+39/+nfrWhWARi2KrivSAIJML0BDDt6lldLMO7XPX/b91fI7nvm72u+fzXViegFgLEwvAHSE6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBO1MJpO21wFgNIx0AYJEFyBIdAGCRBcgSHQBgkQXIEh0AYJEFyBIdAGCRBcgSHQBgkQXIEh0AYJEFyBIdAGCRBcgSHQBgkQXIEh0AYJEFyBIdAGCRBcgSHQBgkQXIEh0AYJEFyBIdAGCRBcgaHfhjUeOTVIrAjAUZ06f2Jl3m5EuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkDQbtsrANAH+3vHa7mfnclkMvfG3SPH5t8IwExnTp/YmXeb6QWAINEFCBJdgCAH0lo2PTl//lW3tLgmQIIDaQA1W3QgzUi3Q2aNeueNhDf5v8tG0olR96zTbozwtzfvdKZZ+8Y6bJv6GekC1MwpYwAdYXphBge3PAbQFNMLADUzvQAMyv7e8do+CyFt4fTCsiOiAClDmfIyvQAj47S95i2aXhBdgJq5OAI6KPl2eShvzYfASJfBG3NwVr0akXqZXmArY45WXTyGyw3pBUJ0GaUhPYnpF+fpAnSEkW6HLDvZe51PGVtm1ujPedn9ssr2XnXbJbb9Ovt3E9+fZHoBBsS0SfeJLqPhgBXzJPcN0W2B0Ujzmr6yqqknqX1j+ESXtRkxwuYai64nJmlN73P2aepgpMuoCSlpostCXZ1jTK7XUH8W7RBdeq0PI9Whh7QP26BLXJEG0BFGugA183m6LerT27I+rWvf9PWxbWLapAuPRZvTQUa6I9WFHR+GauMDaS8981R14xiemMte/dZ5dRz6gZV52jgLYNrYHu+61PEiPNZ9fpZRn71gRLecJwvTPGe2N+roMiyCQB+IbgcZXbZPwGnK6KLryURb7HuU0kJ0xzqK69MTbtt19efDmzfv9972+eUAZPNckQbQEYOcXgBo0yiuSOvqW9AurVeX1mVa8g8OdmFapI3pt65u+7a18bgY6TZk1SfWphvdk6j/lm3DxDYe6/GXpo3u7IWm2EEZAi/YzRPdgfNi0B2rBG3W9lp2RsG274jsG1miCyNndJtVS3S79AcB7UDdYntspuk/8V73/bI6I11KKZ6MbWrrsTe90A7RBViizhdG0YUWtHVO8DQj3Ha4DBigI2Ij3U0/ZMOcFNA3phegBV0644cs0QUIMqcL0BGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQtDOZTNpeB4DRMNIFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYCg3YU3Hjk2Sa0IwFCcOX1iZ95tRroAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoANdnfO770/+xMJvP/DJq/kQawPn8jDaAjRBcgSHQBggYX3VUmspnP4wfNciANGLX9vePl/KtuqfU+HUgDovr0jqnu4C4jutBBfYnWvPVMh6xPTC8Ag9bE9MEyphfCVh2lrPL/mhzx9GU0RX26ts3rXJ91Rt1tPg5GuvRSG6MXxmfT/cxId4GuvfLzSrO2UZ+Da5/rjyb2s62j2/cdqM9P3iFqI7Dpfdg+N25bR9cO1H1demFcti6p/Wl6PdrYh7u0TcgypwtQM3O6I2MUBd3Vu+gKynJdO0UGVjWG/dT0wgacrtRPthsp0emFPrxSbbuOY3/iJk5ob8LQtlvbF9d0+Wd3mZEuQM0cSFvBpq/K276aGw0wT9dHsuvq07o2SXT/36ZvPbd9y3ru99sxu63u7bPo/lY5IJrYf+q6z6FN72xqreg2PaoTnP7tmGPbZnVvn2X3tyyy697fqj+njvtkNnO6ABuad0ZMa3O6RrbAkG3yLsBIF6Bmzl4A6AjRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCNoouvt7x+teD4C4Nlq2M5lM5t64e+TY/BsBmOnM6RM7824zvQA90Id3l31Yxy4QXVbmSbW5bR+786+6paY1aU7X17Er+6/ohjW14RP32/UnVZf16bHrQpyaWIdVt0HTv785XXptf+94r4JGP627ny2a0xVdlhI2WI8DaWylr8HtwttkOJfo0gltzuGtQsC7o+/bQnRX1PcNvYo2f8euj6brWL8x7ENN2eSAbhOPdx33aU53wMzFQjsGOadr1LDcvOB67OiDoe6nRrqMjncANC0+0u3LK1Rf1nMbTf6Odd93ansMMbirPHZd2t+7tC5pjUS3L0eN113Pru8os9avycBsc9/pdU1tu21/zqbfv8pjl3ixWXX9h/DCt+m2Mr0ANG5sUzqDPJAGdFP6XUzfbBzdbd5GLfverr+N55Vss+YlH+NtfpbALmZ6AWBL506ftD69YGQLDNk6o3sjXYCatT7SBeAs0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCFopuvt7xxcun/vvucuL/u+yf9ddh3XXZ9nXNrnvZb/PsnVZ9bFb5ecv+9qq/3fV32fez1hknXVdtE7zvneVdV11P1q0but+vanbV13fc2/fZj1WvW2Tx2iT586y58y8+11l+y9bp2V2JpPJ3Bt3jxybfyMAr7C/d7y86rKrd+bdLroANTtz+sTc6JrTBQgSXYCghdMLANTLSBcgSHQBgkQXIEh0AYJEFyBIdAGCRBcgSHQBgkQXIEh0AYJEFyBIdAGCRBcgSHQBgkQXIEh0AYJEFyBIdAGCRBcgSHQBgkQXIEh0AYJEFyBIdAGCRBcgSHQBgkQXIGh34Y1Hjk1SKwIwFGdOn9iZd5uRLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5A0G7bKwDQB/t7x2u5n53JZDL3xt0jx+bfCMBMZ06f2Jl3m+kFgCDRBQgSXYAgB9JaNj05f/5Vt7S4JkCCkS5AkLMXAGq26OwF0wsdMmuqYd70wyb/d9n0RWKqY9a5jqZVtjfvHNJZ+8Y6bJv6GekC1MxId00ObnkMoClGugA1c0UaMCj7e8dr+yyEtIXTC8sm5wFShjLlZXoBRsYZJM1bNL0gugA1c/YCdFDy7fJQ3poPgQNpAEGmFxi8MY/yVr0akXqZ02UrY45WXTyGyw3pBUJ0GaUhPYnpF9HtiWUne6/zgTfLzAqR87L7ZZXtveq2S2z7dfbvJr4/SXRhQIzgu090GQ1zp8yT3DdEtwVGI81r+sqqpp6k9o3hE13WZsQIm2ssup6YpDW9z9mnqYOPdgToCNMLDJ7RK2nmdFmoqwd2kus11J9FO0SXXuvDSHXoIe3DNugS0QUI8nm6LerTCKFP69o3fX1smxjBd+GxaPOdiZHuSHVhx4eh2nh64aVnnqpuHMMTc9mr3zqvjkOf45unjQNS08b2eNeljhfhse7zs4x6TteIbjlPFqZ5zmxv1NFlWASBPnBFGkBHGOm2xFv69hk105TRTS94MtEW+x6ltBDdsY7i+vSE23Zdk79rnx7XOs37vbd9fjnro3mjG+kCtGkUV6R1dTTUpfXq0rpMS/7BwS6M0Nt4J9jVbd+2Nh4XI92GrPrE2nSjexL137JtmNjGY50KbJrphZrYQRkCL9jNE92B82LQHasEbdb2WnZwa9t3RPaNLNGFkTO6zXJFGkBHrDzS7dJfYfWq3S22x2aaetxsj/aZXqCU4snYprYee3O67RBdgCXqfGEUXWhBWxdiTDPCbUcnorvp9d7eHgF904nowth06eAzWaILEOQ8XYCOEF2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQjamUwmba8DwGgY6QIEiS5AkOgCBIkuQJDoAgSJLkDQ/wFK8XSM+XoOoQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x864 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "motif_size = 64\n",
    "rand_idx = np.random.randint(0, len(rolls))\n",
    "random_roll = rolls[rand_idx]\n",
    "song = random_roll[:, :2 * motif_size] \n",
    "bin_song = song > 0\n",
    "plt.figure(figsize=(6, 12))\n",
    "plt.subplot(4, 1, 1)\n",
    "sn.heatmap(song, cbar=False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])\n",
    "plt.subplot(4, 1, 2)\n",
    "sn.heatmap(song > 0, cbar=False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])  \n",
    "plt.subplot(4, 1, 3)\n",
    "states = roll_to_state(song > 0)\n",
    "sn.heatmap(states, cbar=False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])\n",
    "plt.subplot(4, 1, 4)\n",
    "roll = state_to_roll(states)\n",
    "sn.heatmap(roll, cbar=False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793c9254",
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_size = 8\n",
    "paths = [\n",
    "    'samples/music/giantpiano/',\n",
    "    'samples/music/classical/',\n",
    "    'samples/music/jazz/',\n",
    "    'samples/music/maestro/',\n",
    "    'samples/music/mfiles/',\n",
    "    'samples/music/midiworld/',\n",
    "]\n",
    "try:\n",
    "    dataset = torch.load(\n",
    "        'samples/dataset.pt', map_location=torch.device('cpu')\n",
    "    )\n",
    "except IOError:\n",
    "    dataset = MotifDataset(paths, motif_size=motif_size, bits=16, notespbeat=20, multitokens=True)\n",
    "    torch.save(dataset, 'samples/dataset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e6072c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "net_multi = MusicTransformer(encoder_depth=64, decoder_depth=64, multitokens=True, heads=16)\n",
    "n_param = sum(\n",
    "    p.numel() for p in net_multi.parameters() if p.requires_grad\n",
    ")\n",
    "print('Network ready {:d} parameters'.format(n_param))\n",
    "\n",
    "dataset.multitokens = True\n",
    "train_loader = DataLoader(\n",
    "    dataset, batch_size, True, num_workers=1\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset, batch_size, num_workers=1\n",
    ")\n",
    "\n",
    "net_multi.fit(train_loader, val_loader, epochs=500, patience=500)\n",
    "net_multi.save_model('weights/all_multi.pt')\n",
    "# net_multi.load_model('weights/all_multi.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c77c67d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "net_state = MusicTransformer(bits=16, encoder_depth=64, decoder_depth=64, multitokens=False, heads=16)\n",
    "n_param = sum(\n",
    "    p.numel() for p in net_state.parameters() if p.requires_grad\n",
    ")\n",
    "print('Network ready {:d} parameters'.format(n_param))\n",
    "\n",
    "dataset.multitokens = False\n",
    "train_loader = DataLoader(\n",
    "    dataset, batch_size, True, num_workers=1\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset, batch_size, num_workers=1\n",
    ")\n",
    "\n",
    "net_state.fit(train_loader, val_loader, epochs=500, patience=500)\n",
    "net_state.save_model('weights/all_state.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9bf0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_idx = np.random.randint(0, len(rolls))\n",
    "random_roll = rolls[rand_idx]\n",
    "random_tpb = tpb[rand_idx]\n",
    "random_motif = random_roll[:, :motif_size].astype(np.float32)\n",
    "random_vel = np.mean(random_motif[random_motif > 0])\n",
    "song = random_roll[:, :motif_size + motif_size] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0299141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_song, pred_song = net_multi.song((random_motif > 0).astype(np.float32), 1)\n",
    "plt.figure(figsize=(12, 18))\n",
    "plt.subplot(3, 1, 1)\n",
    "sn.heatmap(p_song, cbar=False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])\n",
    "plt.subplot(3, 1, 2)\n",
    "sn.heatmap(pred_song, cbar=False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])\n",
    "plt.subplot(3, 1, 3)\n",
    "sn.heatmap(song, cbar=False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98522647",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_states = roll_to_state(random_motif > 0, 16, 128)\n",
    "p_song, pred_song = net_state.song(random_states.astype(np.float32), 1)\n",
    "plt.figure(figsize=(12, 18))\n",
    "plt.subplot(3, 1, 1)\n",
    "new_motif = state_to_roll(pred_song[:, random_states.shape[-1]:], bits=8, notes=128)\n",
    "final_song = np.concatenate([\n",
    "    random_motif,\n",
    "    new_motif[:, :motif_size]\n",
    "], axis=1)\n",
    "# sn.heatmap(final_song, cbar=False)\n",
    "sn.heatmap(p_song, cbar=False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])\n",
    "plt.subplot(3, 1, 2)\n",
    "sn.heatmap(final_song, cbar=False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])\n",
    "plt.subplot(3, 1, 3)\n",
    "sn.heatmap(song[:, :final_song.shape[1]], cbar=False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fba9ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
